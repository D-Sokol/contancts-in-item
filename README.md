# Описание

Данный проект позволяет определять, содержит ли то или иное объявление контактную информацию в каких-либо полях, а также выделить точное местонахождение этой информации в предположении, что она находится в описании.


# Формат входных данных

Ожидается, что датасеты с объявлениями представляют собой csv-файлы со следующим набором полей:
* `title` - заголовок (текст),
* `description` - описание (текст),
* `category` - категория (одна строка из списка допустимых категорий),
* `price` - цена (неотрицательное вещественное число),
* `is` - целевая переменная (0 или 1). Может отсутствовать в тестовых наборах данных.

Также в датасетах могут присутствовать другие поля, которые не будут использоваться для получения результатов.


# Формат выходных данных

## Часть 1
Первый из сгенерированных файлов содержит оценки вероятности наличия контактных данных в каждом из объявлений в тестовом датасете.

Пример выходного файла:

|index|prediction|
|-----|----------|
|0    |0.42      |
|1    |0.05      |
|2    |0.94      |


## Часть 2
Второй из сгенерированных файлов содержит оценки положения контактной информации в описаниях объявлений.
Положение задается индексами первого и последнего символов, относящихся к искомой подстроке.
В случаях, когда контактная информация в поле `description` отсутствует, в качестве обоих индексов используется значением `NaN`.

Пример выходного файла:

|index|start|end|
|-----|-----|---|
|0    |3    |15 |
|1    |40   |52 |
|2    |nan  |nan|
|3    |152  |166|


# Использование проекта

Для запуска проекта требуется задать следующие переменные окружения:
```sh
# Путь к директории, содержащей файл train.csv
DATA_ROOT=/path/to/train/data
# Путь к директории, содержащей файл test.csv
TEST_DATA_ROOT=/path/to/test/data
# Директория для записи выходных данных (необязательно)
OUTPUT_ROOT="$TEST_DATA_ROOT"
# Метка, используемая в имени выходных файлов (необязательно)
MODEL=cii_net
```


## Обучение
Результатом стадии обучения являются словарь токенов (файл `weights/vocabulary.json`) и веса обученной модели (файл `weights/model-50.pth`).
Эти файлы создаются при помощи следующих команд:

1. Создание словаря:
```
python3 lib/preprocess.py --input $DATA_ROOT/train.csv --output weights/vocabulary.json
```

2. Обучение модели и создание словаря токенов (если он не был создан отдельно):
```
python3 lib/network.py
```


## Тестирование/инференс
Для тестирования необходимо предварительно создать словарь токенов (файл `weights/vocabulary.json`) и веса обученной модели (файл `weights/model.pth`).

Для генерации выходных данных используется следующая команда:
```
python3 lib/run.py
```
